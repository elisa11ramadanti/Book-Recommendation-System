# -*- coding: utf-8 -*-
"""Proyek Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lU5LP48Jssd_kk1B9GblPDl4dF-A4mnw

**Laporan Proyek Sistem Rekomendasi Buku**

**Nama: Elisa Ramadanti**

# **Project Overview**


**Latar Belakang** :

Sistem rekomendasi buku menjadi semakin penting di era digital, di mana jumlah buku yang tersedia sangat besar dan pengguna sering kali kesulitan menemukan buku yang sesuai dengan preferensi mereka. Sistem ini bertujuan untuk membantu pengguna menemukan buku yang relevan berdasarkan riwayat interaksi mereka, seperti rating atau pembelian.

**Pentingnya Proyek** :

Proyek ini penting karena:

1. Membantu pengguna menghemat waktu dalam mencari buku yang sesuai dengan minat mereka.
2. Meningkatkan pengalaman pengguna dalam menjelajahi konten baru.

**Riset/Referensi** : Sistem rekomendasi banyak digunakan di platform seperti Amazon, Goodreads, dan Google Books.

  *  [Amazons](https://www.amazon.com/?spm=5aebb161.2ef5001f.0.0.14b05171p7gXjn)
  *  [Google Books](https://books.google.com/)
  *  [Goodreads Recommendation System](https://www.goodreads.com/)

# **Business Understanding**

**Problem Statements**
  -  Bagaimana memberikan rekomendasi yang relevan berdasarkan riwayat interaksi pengguna (seperti rating atau pembelian)?

**Goals**
-  Mengembangkan sistem rekomendasi yang dapat memberikan rekomendasi buku yang akurat untuk meningkatkan kepuasan pengguna.

**Solution Approach**
-  Menggunakan Collaborative Filtering dengan merekomendasikan buku berdasarkan interaksi pengguna, seperti rating yang diberikan terhadap buku. Metode yang digunakan adalah Singular Value Decomposition (SVD) dari pustaka Surprise untuk memberikan rekomendasi berdasarkan pola interaksi pengguna lain yang memiliki preferensi serupa.

# **Data Understanding**

**Informasi Dataset:**

-  **Jumlah Data:** Dataset ini memiliki 6810 baris dan 12 kolom.

-  **Kondisi Data** :
    - Terdapat beberapa missing values pada kolom s*ubtitle, categories, thumbnail, description, published_year, average_rating, num_pages*, dan *ratings_count.*
    -  Tidak ada data duplikat berdasarkan pengecekan dengan df.duplicated().sum().
-  **Sumber Data:** Dataset ini diambil dari [Kaggle: Books Dataset](https://www.kaggle.com/datasets/abdallahwagih/books-dataset/data)

-  **Uraian Fitur Dataset:**
    - isbn13, isbn10: Identifikasi unik buku.
    - title, subtitle: Informasi tentang judul buku.
    - authors: Penulis buku.
    - categories: Kategori buku.
    - thumbnail: URL gambar sampul buku.
    - description: Deskripsi buku.
    - published_year: Tahun publikasi.
    - average_rating: Rating rata-rata buku.
    - num_pages: Jumlah halaman.
    - ratings_count: Jumlah rating yang diterima.

## **Import Library**
"""

# Install Surprise
!pip install scikit-surprise

# Import Library
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from surprise import Dataset, Reader, SVD
from surprise import accuracy
from surprise.model_selection import train_test_split
from surprise.model_selection import cross_validate

"""**Download dataset**"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("abdallahwagih/books-dataset")

print("Path to dataset files:", path)

# Path to the downloaded dataset
path = "/root/.cache/kagglehub/datasets/abdallahwagih/books-dataset/versions/1"

# Check the contents of the directory to find the actual filename
print("Files in dataset directory:")
for filename in os.listdir(path):
    print(filename)

"""## **Data Loading**"""

# Load Dataset
filename = 'data.csv'
df = pd.read_csv(os.path.join(path, filename))
df.head()

"""### **Informasi Dataset**"""

df.info()

"""**Insight**

-  Jumlah Data: 6810 entri, 12 kolom.
-  Tipe Data:
    1. Numerik: 4 kolom (published_year, average_rating, num_pages, ratings_count).
    2. Objek/Teks: 7 kolom (isbn10, title, subtitle, authors, categories, thumbnail, description).
    3. Integer: 1 kolom (isbn13).

**Menampilkan Missing Value**
"""

df.isnull().sum()

"""**insight**:

Berikut adalah jumlah missing values untuk setiap kolom:

1. subtitle: 4429 missing (sekitar 65% data hilang)
2. authors: 72 missing (sekitar 1% data hilang)
3. categories: 99 missing (sekitar 1% data hilang)
4. thumbnail: 329 missing (sekitar 5% data hilang)
5. description: 262 missing (sekitar 4% data hilang)
6. published_year: 6 missing (hampir tidak ada missing value)
7. average_rating: 43 missing (sekitar 0.6% data hilang)
8. num_pages: 43 missing (sekitar 0.6% data hilang)
9. ratings_count: 43 missing (sekitar 0.6% data hilang)

-  Kolom isbn13, isbn10, dan title tidak memiliki missing values

**Menampilkan Data Duplikat**
"""

df.duplicated().sum()

"""**Insight:**

Tidak memiliki data duplikat

**Visualisasi Distribusi Rating**
"""

# Visualisasi Distribusi Rating
plt.figure(figsize=(10, 6))
sns.histplot(df['average_rating'], bins=30, kde=True, color='blue')
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

"""**Insight :**

Sebagian besar buku memiliki rating terbanyak di antara 3.5 hingga 4.5.

# **Data Preprocessing**

**Penambahan user_id Berdasarkan Indeks**
"""

# Tambahkan user_id berdasarkan indeks
df['user_id'] = df.index

"""**Insight:**

Memberikan identifier unik untuk setiap user menggunakan indeks dataframe.

**Menangani missing values**
"""

df_cleaned = df.dropna(subset=['ratings_count', 'average_rating'])

"""**Insight:**

Menghapus missing values pada kolom average_rating dan ratings_count agar tidak memengaruhi perhitungan dalam sistem rekomendas

**Konversi Tipe Data**
"""

# Konversi tipe data agar sesuai untuk Collaborative Filtering
df_cleaned.loc[:, 'isbn13'] = df_cleaned['isbn13'].astype(str)
df_cleaned.loc[:, 'user_id'] = df_cleaned['user_id'].astype(str)

"""**Insight**:

Mengonversi tipe data isbn13 dan user_id menjadi string untuk memastikan konsistensi
"""

# Cek data setelah pembersihan
print("\nData Setelah Pembersihan:")
df_cleaned[['user_id', 'isbn13', 'ratings_count','average_rating']].head()

"""### **Collaborative Filltering Preparation**"""

# Persiapkan data untuk Surprise Library
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df_cleaned[['user_id', 'isbn13', 'average_rating']], reader)

"""**Insight:**

Collaborative Filtering menggunakan User-Item Matrix yang dibangun dari isbn13, dan average_rating

**Split data**
"""

# Split data menjadi train dan test set
trainset, testset = train_test_split(data, test_size=0.2)

"""Data dibagi menjadi dua bagian: **Train Set** dan **Test Set** dengan proporsi **80% untuk Train Set** dan **20% untuk Test Set**.

# **Modeling**

Pada tahap ini, akan mengimplementasikan pendekatan sistem rekomendasi: **Collaborative Filtering**

**Collaborative Filtering**

*   **Cara Kerja:** Merekomendasikan buku berdasarkan pola interaksi pengguna lain yang serupa (misalnya, rating atau pembelian).

*   **Algoritma yang Digunakan:** Singular Value Decomposition (SVD) dari pustaka Surprise.

**Proses ini menggunakan algoritma SVD (Singular Value Decomposition) untuk melakukan Collaborative Filtering.**
"""

# Gunakan algoritma SVD untuk Collaborative Filtering
algo = SVD()

"""**insight**:

SVD adalah teknik dekomposisi matriks yang digunakan untuk mengurangi dimensi data dan menangkap pola interaksi pengguna
"""

# Train model menggunakan seluruh data
trainset = data.build_full_trainset()
algo.fit(trainset)

# Fungsi untuk memberikan rekomendasi
def recommend_books(user_id, n_recommendations=5):
    # Ambil list ISBN yang pernah dirating user
    rated_books = df_cleaned[df_cleaned['user_id'] == user_id]['isbn13'].tolist()
    all_books = df_cleaned['isbn13'].unique()

    # Prediksi rating untuk semua buku yang belum pernah dirating
    predictions = []
    for book in all_books:
        if book not in rated_books:
            pred = algo.predict(user_id, book)
            predictions.append((book, pred.est))

    # Urutkan prediksi berdasarkan rating tertinggi
    predictions.sort(key=lambda x: x[1], reverse=True)

    # Ambil top-N rekomendasi
    recommended_books = predictions[:n_recommendations]
    return recommended_books

# Contoh penggunaan fungsi rekomendasi
user_id = '3' # Input User
recommended_books = recommend_books(user_id)

print(f"Rekomendasi Buku untuk User: {user_id}")
print("| Rank | Judul Buku                       | Prediksi Rating |")
print("|------|----------------------------------|-----------------|")
for rank, (isbn, rating) in enumerate(recommended_books, start=1):
    book_title = df[df['isbn13'] == int(isbn)]['title'].values[0]
    print(f"|    {rank} | {book_title[:30]:<32} | {rating:.2f}            |")

# Fungsi untuk menampilkan visualisasi Top-N Rekomendasi
def visualize_recommendations(recommended_books, n_recommendations=5):
    # Ambil judul buku dan prediksi rating
    book_titles = []
    ratings = []

    for isbn, rating in recommended_books:
        title = df[df['isbn13'] == int(isbn)]['title'].values[0]
        book_titles.append(title[:30])  # Maksimal 30 karakter untuk judul
        ratings.append(rating)

    # Membuat bar plot menggunakan Seaborn
    plt.figure(figsize=(10, 6))
    sns.barplot(x=ratings, y=book_titles, palette='Blues')
    plt.xlabel('Prediksi Rating')
    plt.title(f'Top-{n_recommendations} Rekomendasi Buku untuk User {user_id}')
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    plt.show()

# Contoh penggunaan visualisasi
visualize_recommendations(recommended_books)

"""# **Evaluation**

**Evaluasi ini menggunakan:**

-  RMSE (Root Mean Square Error): Mengukur rata-rata kesalahan kuadrat.
-  MAE (Mean Absolute Error): Mengukur rata-rata kesalahan absolut.

**Evaluasi Model menggunakan Test Set**
"""

# Evaluasi model pada test set
predictions = algo.test(testset)
print("\nEvaluasi Model:")
rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)

"""**Insight:**

-  RMSE (Root Mean Squared Error) = 0.2473 dan MAE (Mean Absolute Error) = 0.1736 menunjukkan bahwa model memiliki error yang relatif rendah dalam memprediksi rating pengguna.
- Nilai MAE yang lebih kecil dari RMSE mengindikasikan bahwa sebagian besar prediksi cukup akurat, namun ada beberapa error yang lebih besar yang mempengaruhi RMSE.

**Evaluasi dilakukan menggunakan Cross Validation dengan metrik RMSE dan MAE.**
"""

# Evaluasi model dengan Cross Validation
cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

"""**Insight:**
-  Hasil evaluasi menunjukkan Rata-rata RMSE = 0.3304 dan MAE = 0.2312 pada 5-fold cross-validation menunjukkan performa yang cukup konsisten di setiap fold.

# **Conclusion**

- Sistem rekomendasi buku berhasil dibangun menggunakan Collaborative Filtering dengan metode SVD.
- Model memberikan rekomendasi yang relevan berdasarkan pola interaksi pengguna lain yang memiliki preferensi serupa.
- Hasil evaluasi menunjukkan RMSE sebesar 0.2473 dan MAE sebesar 0.1736, menandakan prediksi yang akurat.
- Top-5 rekomendasi buku berhasil ditampilkan dengan prediksi rating tertinggi bagi pengguna.
- Sistem ini membantu pengguna menemukan buku yang sesuai dengan preferensi mereka, meningkatkan pengalaman membaca.
"""